{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd066057fed053cfb35cdbc6ba2ea2926e1c5433485c4b2c3fbfc6095ea3d1e7403",
   "display_name": "Python 3.8.8 64-bit ('pytorch_env': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "66057fed053cfb35cdbc6ba2ea2926e1c5433485c4b2c3fbfc6095ea3d1e7403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "linear_model_dropout(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=3, bias=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple linear model with and without dropout\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "class linear_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_model, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(nn.Linear(1, 8),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(8, 16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16, num_classes),\n",
    "                                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.layers(input)\n",
    "        return output\n",
    "\n",
    "model = linear_model()\n",
    "\n",
    "## With dropout\n",
    "class linear_model_dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_model_dropout, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(nn.Linear(1, 8),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(8, 16),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16, num_classes),\n",
    "                                    nn.Dropout(0.2)\n",
    "                                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.layers(input)\n",
    "        return output\n",
    "\n",
    "model_dropout = linear_model_dropout()\n",
    "model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementing a simple CNN model\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2, dilation=1, groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            ) # padding = (kernel_size-1)/2 if stride == 1; to keep the size the same\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2, dilation=1, groups=1, bias=True, padding_mode='zeros'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Linear(32*7*7, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.classifier(x)\n",
    "        return output, input\n",
    "\n",
    "cnn = CNN() # initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=12, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=12, out_features=3, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=128, out_features=784, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement and autoencoder model\n",
    "\"\"\"\n",
    "input_dim, output_dim = 28*28, 3\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, output_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement and convolutional autoencoder model\n",
    "\"\"\"\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Seqential(\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Seqential(\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementing a Recurrent Neural Network\n",
    "\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = INPUT_SIZE,\n",
    "                            hidden_size = HIDDEN_SIZE,\n",
    "                            num_layers = NUM_LAYERS,\n",
    "                            batch_first = True,)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input: (batch_size, time_steps, input_size)\n",
    "        # r_out: (batch, time_steps, output_size)\n",
    "        # h_n: (num_layers, batch, hidden_size)\n",
    "        # h_c: (num_layers, batch, hidden_size)\n",
    "\n",
    "        r_out, (h_n, h_c) = self.rnn(input, None) # None is zero initial hidden state this can be initialized to something different\n",
    "\n",
    "        outputs = []\n",
    "        for time_step in range(r_out.size(1)):\n",
    "            outputs.append(self.classifier(r_out[:, time_step, :]))\n",
    "        return outputs\n",
    "\n",
    "        rnn = RNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.6368e+00,  1.1792e+00,  1.5518e-01,  ...,  1.1461e+00,\n",
       "          -4.1128e-01, -4.2018e-01],\n",
       "         [ 1.0277e+00,  3.5833e-01,  6.8092e-01,  ...,  2.0366e+00,\n",
       "           2.9316e-01, -8.7804e-01],\n",
       "         [ 1.8258e+00,  4.0460e-01,  9.1646e-01,  ...,  2.2820e+00,\n",
       "          -1.5511e+00, -6.7027e-01],\n",
       "         ...,\n",
       "         [ 8.3025e-01,  5.8283e-01, -7.2893e-01,  ...,  3.5586e-01,\n",
       "          -6.4762e-01, -8.5525e-02],\n",
       "         [ 1.5338e+00, -8.6511e-01,  1.4728e-01,  ...,  1.4880e+00,\n",
       "          -1.1971e+00, -8.1198e-01],\n",
       "         [ 5.4968e-01, -9.0485e-03, -5.1379e-01,  ...,  1.6863e+00,\n",
       "          -5.1742e-01, -1.8732e+00]],\n",
       "\n",
       "        [[ 1.6108e+00,  4.5624e-01, -1.9615e-01,  ...,  1.4987e+00,\n",
       "          -7.5927e-01, -9.4880e-01],\n",
       "         [ 1.0540e+00,  4.3374e-02, -3.0847e-01,  ...,  1.5350e+00,\n",
       "           1.3023e-01, -8.1148e-01],\n",
       "         [ 1.5210e+00, -1.0944e-01,  7.2690e-01,  ...,  1.1882e+00,\n",
       "           3.0945e-01, -1.4730e+00],\n",
       "         ...,\n",
       "         [ 1.0626e+00,  6.4100e-02, -9.3394e-01,  ...,  7.5799e-01,\n",
       "          -1.0761e+00,  1.6228e-01],\n",
       "         [ 8.6073e-01,  2.7455e-01,  9.9600e-02,  ...,  1.0145e+00,\n",
       "           4.8132e-01, -3.0473e-01],\n",
       "         [ 8.7076e-01, -2.3908e-01, -1.9779e-01,  ...,  8.0520e-01,\n",
       "          -3.4965e-01, -6.9621e-01]],\n",
       "\n",
       "        [[ 1.3627e+00, -5.5806e-01, -9.6795e-01,  ...,  9.1672e-01,\n",
       "          -4.8447e-01, -7.1835e-01],\n",
       "         [ 1.1548e+00,  8.9984e-01, -5.5702e-01,  ...,  8.8535e-01,\n",
       "          -5.8527e-01, -1.8985e-01],\n",
       "         [ 1.3624e+00,  3.1219e-01, -5.8682e-01,  ...,  4.7780e-01,\n",
       "          -3.2779e-01, -7.2930e-01],\n",
       "         ...,\n",
       "         [ 1.4514e+00,  7.1190e-01, -1.5990e-01,  ...,  1.2639e+00,\n",
       "          -4.7700e-01, -8.2716e-01],\n",
       "         [ 2.4204e+00, -2.8446e-01, -2.0249e-03,  ...,  1.7352e+00,\n",
       "          -7.1227e-01, -8.1564e-01],\n",
       "         [ 1.5887e-01,  3.5072e-01,  4.4936e-01,  ...,  8.7126e-01,\n",
       "          -7.0732e-01, -9.2138e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.0960e-01,  1.2736e-01, -6.0553e-01,  ...,  1.8578e+00,\n",
       "          -9.5669e-01, -3.2567e-01],\n",
       "         [ 1.1163e+00, -3.4204e-01,  2.5759e-01,  ...,  1.2041e+00,\n",
       "           6.9512e-01, -1.1260e+00],\n",
       "         [ 1.3768e+00,  6.3790e-01,  6.8142e-01,  ...,  1.1525e+00,\n",
       "          -2.0634e-01, -1.1412e+00],\n",
       "         ...,\n",
       "         [ 2.0070e+00,  3.1109e-01, -6.3031e-01,  ...,  1.0491e+00,\n",
       "          -4.3331e-01, -1.1353e+00],\n",
       "         [ 1.6642e+00,  4.1040e-01,  2.1323e-01,  ...,  5.8833e-01,\n",
       "           2.5431e-01, -7.9922e-01],\n",
       "         [ 1.4401e+00,  5.9653e-01,  2.9292e-01,  ...,  1.5098e+00,\n",
       "          -1.2800e-01, -7.3851e-01]],\n",
       "\n",
       "        [[ 1.6522e+00,  3.5515e-01, -9.4999e-01,  ...,  1.2849e+00,\n",
       "          -1.3408e-01, -8.9946e-01],\n",
       "         [ 1.6969e+00, -3.8437e-01,  3.8181e-01,  ...,  1.3241e+00,\n",
       "          -1.4372e-02, -5.7932e-01],\n",
       "         [ 1.0135e+00,  2.2527e-01,  6.2323e-01,  ...,  8.2874e-01,\n",
       "          -3.7153e-01,  4.3691e-02],\n",
       "         ...,\n",
       "         [ 1.6106e+00, -1.0428e+00, -3.5160e-01,  ...,  2.2035e+00,\n",
       "          -3.2621e-02, -4.0339e-01],\n",
       "         [ 1.3114e+00,  4.5753e-01, -1.2811e-01,  ...,  1.4881e+00,\n",
       "          -3.1975e-01, -1.3406e+00],\n",
       "         [ 8.6626e-01,  3.6426e-01,  5.6253e-01,  ...,  5.2658e-01,\n",
       "           6.5911e-02, -1.0210e+00]],\n",
       "\n",
       "        [[ 1.5078e+00,  1.8383e-01, -2.6380e-01,  ...,  2.3649e+00,\n",
       "          -1.4567e+00, -1.0031e+00],\n",
       "         [ 1.0183e+00,  5.5753e-01, -5.4611e-01,  ...,  1.2331e+00,\n",
       "          -2.9021e-01, -1.7807e-01],\n",
       "         [ 1.0697e+00,  1.2287e-01,  1.2171e+00,  ...,  1.4892e+00,\n",
       "          -6.3860e-01, -1.2205e+00],\n",
       "         ...,\n",
       "         [ 1.2134e+00, -5.9571e-01, -9.7667e-01,  ...,  1.3693e+00,\n",
       "          -1.2418e+00, -1.4003e+00],\n",
       "         [ 1.7996e+00, -2.5092e-01, -4.6701e-02,  ...,  1.6857e+00,\n",
       "          -1.1003e+00, -8.2486e-01],\n",
       "         [ 7.6384e-01, -4.8959e-01, -3.9059e-01,  ...,  1.0733e+00,\n",
       "           7.5817e-02, -2.0470e+00]]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "\"\"\"\n",
    "A Transformer model\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.nn import Transformer\n",
    "\n",
    "# d_model – the number of expected features in the encoder/decoder inputs (default=512)\n",
    "# nhead – the number of heads in the multiheadattention models (default=8)\n",
    "# num_encoder_layers – the number of sub-encoder-layers in the encoder (default=6)\n",
    "# num_decoder_layers – the number of sub-decoder-layers in the decoder (default=6)\n",
    "# dim_feedforward – the dimension of the feedforward network model (default=2048)\n",
    "# dropout – the dropout value (default=0.1)\n",
    "# activation – the activation function of encoder/decoder intermediate layer, relu or gelu (default=relu)\n",
    "# custom_encoder – custom encoder (default=None)\n",
    "# custom_decoder – custom decoder (default=None)\n",
    "\n",
    "# define parameters\n",
    "# src – the sequence to the encoder (required) - (Source_length, Batch_size, Input_dim)\n",
    "# tgt – the sequence to the decoder (required) - (Target_length, Batch_size, Input_dim)\n",
    "# src_mask – the additive mask for the src sequence (optional) - (S, S)\n",
    "# tgt_mask – the additive mask for the tgt sequence (optional) - (T, T)\n",
    "# memory_mask – the additive mask for the encoder output (optional) - (T, S)\n",
    "# src_key_padding_mask – the ByteTensor mask for src keys per batch (optional) - (N, S)\n",
    "# tgt_key_padding_mask – the ByteTensor mask for tgt keys per batch (optional) - (N, T)\n",
    "# memory_key_padding_mask – the ByteTensor mask for memory keys per batch (optional) - (N, S)\n",
    "\n",
    "# where S is the source sequence length, T is the target sequence length, N is the batch size, E is the feature number\n",
    "\n",
    "# output: (T, N, E)(T,N,E) .\n",
    "\n",
    "# Note: Due to the multi-head attention architecture in the transformer model, the output sequence length of a transformer is same as the input sequence (i.e. target) length of the decode.\n",
    "\n",
    "\n",
    "# transformer_model = Transformer(d_model=2048, nhead=16, num_encoder_layers=12)\n",
    "# src = torch.rand(10, 8, 2048)\n",
    "# tgt = torch.rand(20, 8, 2048)\n",
    "# out = transformer_model(src, tgt)\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementing Graph Convolutional Neural Network (GCN)\n",
    "\n",
    "\"\"\"\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from pygcn.layers import GraphConvolution\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}